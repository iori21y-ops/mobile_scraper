name: scheduled-scrape
on:
  workflow_dispatch:     # 수동 실행 시 실행
  push:
    branches: [ main ]   # main 브랜치에 push 될 때마다 실행

permissions:
  contents: write

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"

      - name: Install deps
        run: |
          pip install -r requirements.txt
          python -m playwright install --with-deps

      - name: Run scrape
        env:
          TARGET_URLS: ${{ secrets.TARGET_URLS }}
          CSS_ITEM:    ${{ secrets.CSS_ITEM }}
          CSS_TITLE:   ${{ secrets.CSS_TITLE }}
          CSS_LINK:    ${{ secrets.CSS_LINK }}
          MAX_ITEMS:   ${{ secrets.MAX_ITEMS || 10 }}   # 비어 있으면 기본값 10
        run: python scrape.py

      - name: Commit & push results
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add data/results.json
          git commit -m "update results $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "no changes"
          git push